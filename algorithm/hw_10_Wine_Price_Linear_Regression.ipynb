{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression: Using wine descriptions to predict wine prices\n",
    "\n",
    "Let's add a new tool to our toolbox: **regression**. Basically speaking, it predicts numbers.\n",
    "\n",
    "**Regression** predicts **continuous** variables, like \\$7 or \\$7.50 or \\$9.35. **Normal number stuff.**\n",
    "\n",
    "Previously we've predicted using **classification**, which predicts **categorical** variables, like red vs. white.\n",
    "\n",
    "> You might get confused that when we did classification our categories were numbers - red might be `2` and white might be `1` and dessert wine might be `0`. But!! The reason regression is different is that you'll **never** have the computer say \"oh it's like 1.5, a little more than white and a little less than red.\" With classification, a prediction is always just one specific category.\n",
    "\n",
    "So in short, **if you're trying to predict a number, you want regression.** Let's see how it works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our data\n",
    "\n",
    "### Step 1.1: Read in our data\n",
    "\n",
    "First, we're going to read in our data. It's wine reviews!\n",
    "\n",
    "While we're reading it in, we're also going to convert the alcohol and price levels to integers. They come in as strings because I didn't clean the data very well earlier!\n",
    "\n",
    "**Be sure to move this notebook into the same directory as your wine reviews CSV!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>appellation</th>\n",
       "      <th>bottle size</th>\n",
       "      <th>category</th>\n",
       "      <th>date published</th>\n",
       "      <th>designation</th>\n",
       "      <th>importer</th>\n",
       "      <th>price</th>\n",
       "      <th>taster</th>\n",
       "      <th>url</th>\n",
       "      <th>user avg rating</th>\n",
       "      <th>variety</th>\n",
       "      <th>wine_desc</th>\n",
       "      <th>wine_name</th>\n",
       "      <th>wine_points</th>\n",
       "      <th>winery</th>\n",
       "      <th>alcohol_int</th>\n",
       "      <th>price_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14%</td>\n",
       "      <td>Barolo, Piedmont, Italy</td>\n",
       "      <td>750 ml</td>\n",
       "      <td>Red</td>\n",
       "      <td>9/1/2017</td>\n",
       "      <td>Cannubi</td>\n",
       "      <td>Oliver McCrum Wines</td>\n",
       "      <td>$60,  Buy Now</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>http://www.winemag.com/buying-guide/brezza-201...</td>\n",
       "      <td>Not rated yet [Add Your Review]</td>\n",
       "      <td>Nebbiolo</td>\n",
       "      <td>One of the best expressions from the classic C...</td>\n",
       "      <td>Brezza 2013 Cannubi  (Barolo)</td>\n",
       "      <td>98.0</td>\n",
       "      <td>Brezza</td>\n",
       "      <td>14.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.5%</td>\n",
       "      <td>Barolo, Piedmont, Italy</td>\n",
       "      <td>750 ml</td>\n",
       "      <td>Red</td>\n",
       "      <td>9/1/2017</td>\n",
       "      <td>Vigna Rionda Riserva</td>\n",
       "      <td>Vineyard Brands</td>\n",
       "      <td>$151,  Buy Now</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>http://www.winemag.com/buying-guide/massolino-...</td>\n",
       "      <td>Not rated yet [Add Your Review]</td>\n",
       "      <td>Nebbiolo</td>\n",
       "      <td>From one of the most celebrated vineyards in t...</td>\n",
       "      <td>Massolino 2011 Vigna Rionda Riserva  (Barolo)</td>\n",
       "      <td>98.0</td>\n",
       "      <td>Massolino</td>\n",
       "      <td>14.0</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14%</td>\n",
       "      <td>Barolo, Piedmont, Italy</td>\n",
       "      <td>750 ml</td>\n",
       "      <td>Red</td>\n",
       "      <td>9/1/2017</td>\n",
       "      <td>Monvigliero</td>\n",
       "      <td>Bacchanal Wine Imports</td>\n",
       "      <td>$70,  Buy Now</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>http://www.winemag.com/buying-guide/comm-g-b-b...</td>\n",
       "      <td>Not rated yet [Add Your Review]</td>\n",
       "      <td>Nebbiolo</td>\n",
       "      <td>Always the firm's showstopper and one of the b...</td>\n",
       "      <td>Comm. G. B. Burlotto 2013 Monvigliero  (Barolo)</td>\n",
       "      <td>98.0</td>\n",
       "      <td>Comm. G. B. Burlotto</td>\n",
       "      <td>14.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  alcohol              appellation bottle size category date published  \\\n",
       "0     14%  Barolo, Piedmont, Italy      750 ml      Red       9/1/2017   \n",
       "2   14.5%  Barolo, Piedmont, Italy      750 ml      Red       9/1/2017   \n",
       "3     14%  Barolo, Piedmont, Italy      750 ml      Red       9/1/2017   \n",
       "\n",
       "            designation                importer           price  \\\n",
       "0               Cannubi     Oliver McCrum Wines   $60,  Buy Now   \n",
       "2  Vigna Rionda Riserva         Vineyard Brands  $151,  Buy Now   \n",
       "3           Monvigliero  Bacchanal Wine Imports   $70,  Buy Now   \n",
       "\n",
       "          taster                                                url  \\\n",
       "0  Kerin O’Keefe  http://www.winemag.com/buying-guide/brezza-201...   \n",
       "2  Kerin O’Keefe  http://www.winemag.com/buying-guide/massolino-...   \n",
       "3  Kerin O’Keefe  http://www.winemag.com/buying-guide/comm-g-b-b...   \n",
       "\n",
       "                   user avg rating   variety  \\\n",
       "0  Not rated yet [Add Your Review]  Nebbiolo   \n",
       "2  Not rated yet [Add Your Review]  Nebbiolo   \n",
       "3  Not rated yet [Add Your Review]  Nebbiolo   \n",
       "\n",
       "                                           wine_desc  \\\n",
       "0  One of the best expressions from the classic C...   \n",
       "2  From one of the most celebrated vineyards in t...   \n",
       "3  Always the firm's showstopper and one of the b...   \n",
       "\n",
       "                                         wine_name  wine_points  \\\n",
       "0                    Brezza 2013 Cannubi  (Barolo)         98.0   \n",
       "2    Massolino 2011 Vigna Rionda Riserva  (Barolo)         98.0   \n",
       "3  Comm. G. B. Burlotto 2013 Monvigliero  (Barolo)         98.0   \n",
       "\n",
       "                 winery  alcohol_int  price_int  \n",
       "0                Brezza         14.0       60.0  \n",
       "2             Massolino         14.0      151.0  \n",
       "3  Comm. G. B. Burlotto         14.0       70.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "df = pd.read_csv(\"wine-reviews.csv\")\n",
    "\n",
    "# Clean up alcohol and price and convert to integers\n",
    "df['alcohol_int'] = df.alcohol.str.extract(\"(\\d+)\", expand=False).dropna().astype(int)\n",
    "df['price_int'] = df.price.str.extract(\"(\\d+)\", expand=False).dropna().astype(int)\n",
    "\n",
    "# Get rid of anything without a description or a price\n",
    "df.dropna(subset=['price_int', 'wine_desc'], how='any', inplace=True)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating features\n",
    "\n",
    "Same as with classification, our features need to be **numbers**. The regression model won't recognize words!\n",
    "\n",
    "### Step 2.0: If you aren't analyzing text, you'll just move some columns into `features_df` like\n",
    "\n",
    "```\n",
    "features_df = df[['age','weight']]\n",
    "```\n",
    "\n",
    "but in this case, we *are* analyzing text, so...\n",
    "\n",
    "### Step 2.1: If analyzing text, create your vectorizer\n",
    "\n",
    "Which kind of vectorizer are you using? A **CountVectorizer** to only count values, or a **TfIdfVectorizer** to count percentages? Once you've figured it out, answer the following questions.\n",
    "\n",
    "1. **vocabulary**: are you looking for a specific set of words? It's just a normal list. If you don't give a vocabulary, the computer will figure out the list of words for you (it's pretty good at that!) - so you don't usually use a vocabulary unless you have a REALLY GOOD REASON.\n",
    "1. **ngram_range**: are you only vectorizing single words, or are you also looking at multi-word phrases? By default it only looks for one word `(1,1)`, but you can look for 1-2 word phrases `(1,2)`, only 4-word phrases `(4,4)`, etc.\n",
    "1. **binary**: Do you want to just test to see if a word is included or not, and don't care about counting? `True` or `False`.\n",
    "1. **tokenizer**: are you going to do any stemming or lemmatization, or are you okay with the existing words?\n",
    "1. **stop_words**: do you use stopwords? Stopwords are useless for judging content, but good for judging style. `english` will give default words, or use a list to use multiple.\n",
    "1. **max_features**: if your classifier or regression is too slow, you might want to limit the number of features that the model will use. By default it uses unlimited features, but you can say hey no, use `500` or something like that.\n",
    "1. **max_df**: do you want to not include words that show up in a lot of documents? `0.0`-`1.0` to have a percentage as a ceiling, or an integer to have a maximum number of documents. For example, \"5\" means \"Ignore anything that shows up in more than 5 documents\" \n",
    "1. **min_df**: do you want to not include words that show up in a only a few documents? `0.0`-`1.0` to have a percentage as a floor, or an integer to have a maximum number of documents. For example, \"0.05\" means \"Ignore anything that shows up in fewer than 5% of documents\" \n",
    "1. **use_idf**: do you want to use inverse document frequency, which makes less frequent words more important? (`TfidfVectorizer` only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1: Okay, let's actually create our vectorizer\n",
    "\n",
    "We're going to use a `CountVectorizer`.\n",
    "\n",
    "* We're also going to use stop words, since **\"and\"** and **\"the\"** probably aren't important to wine prices.\n",
    "* We're going to use `max_features=4000` to stick to 4000 features so our regression won't be as terribly slow as with all 6000. It'll still be slow, though!\n",
    "\n",
    "I'm also going to **remove numbers from the description** by feeding our vectorizer `df['wine_desc'].str.replace(\"\\d\",\"\")`. I just don't think numbers matter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abrasive</th>\n",
       "      <th>abundant</th>\n",
       "      <th>accent</th>\n",
       "      <th>accented</th>\n",
       "      <th>accents</th>\n",
       "      <th>accessible</th>\n",
       "      <th>acid</th>\n",
       "      <th>acidic</th>\n",
       "      <th>acidity</th>\n",
       "      <th>acidity drink</th>\n",
       "      <th>...</th>\n",
       "      <th>yellow pear</th>\n",
       "      <th>young</th>\n",
       "      <th>young wine</th>\n",
       "      <th>youthfully</th>\n",
       "      <th>zest</th>\n",
       "      <th>zestiness</th>\n",
       "      <th>zesty</th>\n",
       "      <th>zesty acidity</th>\n",
       "      <th>zinfandel</th>\n",
       "      <th>zippy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abrasive  abundant  accent  accented  accents  accessible  acid  acidic  \\\n",
       "0         0         0       0         0        0           0     0       0   \n",
       "1         0         0       0         0        0           0     0       0   \n",
       "2         0         0       0         0        0           0     0       0   \n",
       "3         0         0       0         0        0           0     0       0   \n",
       "4         0         0       0         0        0           0     0       0   \n",
       "\n",
       "   acidity  acidity drink  ...    yellow pear  young  young wine  youthfully  \\\n",
       "0        1              0  ...              0      0           0           0   \n",
       "1        0              0  ...              0      0           0           0   \n",
       "2        0              0  ...              0      0           0           0   \n",
       "3        1              0  ...              0      0           0           0   \n",
       "4        1              0  ...              0      0           0           1   \n",
       "\n",
       "   zest  zestiness  zesty  zesty acidity  zinfandel  zippy  \n",
       "0     0          0      0              0          0      0  \n",
       "1     0          0      0              0          0      0  \n",
       "2     0          0      0              0          0      0  \n",
       "3     0          0      0              0          0      0  \n",
       "4     0          0      0              0          0      0  \n",
       "\n",
       "[5 rows x 1500 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer(stop_words = 'english',\n",
    "                      max_features = 1500,\n",
    "                      ngram_range=(1,2),\n",
    "                      binary=True, \n",
    "                      token_pattern=r'\\b[a-zA-Z][a-zA-Z]+\\b')\n",
    "# Let's also remove numbers before we count words\n",
    "matrix = vec.fit_transform(df['wine_desc'].str.replace(\"\\d\",\"\"))\n",
    "features_df = pd.DataFrame(matrix.toarray(), columns=vec.get_feature_names())\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing to do the work\n",
    "\n",
    "### Step 3.1: Train/test split\n",
    "\n",
    "Some data you'll train your regression model with, some you'll use for testing. That's how you know how good your model is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3131, 1500) (783, 1500) (3131,) (783,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_df.values, # these are our words\n",
    "    df.price_int, # these are our prices\n",
    "    test_size = 0.2)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing the regression\n",
    "\n",
    "### Step 4.1 Creating and training your model\n",
    "\n",
    "You're just going to use a **linear regression**... because I said so.\n",
    "\n",
    "* **X_train** is our features to learn about (our vectorized descriptions, aka our word counts)\n",
    "* **y_train** is the prices for the wines we're learning about\n",
    "\n",
    "You can look at them individually if you want! This is just telling our model to learn what features might be connected to higher or lower prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=0, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression(fit_intercept = 0)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That error message is okay, don't worry about it! **And if it's taking forever?** You have too many features! Maybe go back up to your `CountVectorizer` and add `max_features=500` so it isn't looking at like 6000 variables at a time. But maybe try it with a lot for the first time, just to see. Go make a coffee or something while you wait."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2 Testing your model\n",
    "\n",
    "To test your model, you say \"hey, how far are my REAL data points from what the regression would have predicted?\" A little math later and this is the [R squared](https://en.wikipedia.org/wiki/Coefficient_of_determination). It's the percent explained by your model. `0.30` would mean \"your predictor explains 30% of the price.\"\n",
    "\n",
    "Speaking practically, the larger the better. 100% would mean you did a perfect job!\n",
    "\n",
    "We show you the R squared for test and train below, **but remember: it's only important for the test data!!!** Being proud of a score with your training data is just silly, since your model is basically cheating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on train: 0.725644876553 \n",
      "Mean Squared Error on train: 215.848315152\n",
      "R2 on test: 0.0178056214745 \n",
      "Mean Squared Error on train: 949.191539435\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print('R2 on train:', r2_score(y_train, lr.predict(X_train)), '\\nMean Squared Error on train:', mean_squared_error(y_train, lr.predict(X_train)))\n",
    "\n",
    "print('R2 on test:', r2_score(y_test, lr.predict(X_test)), '\\nMean Squared Error on train:', mean_squared_error(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did we do? **Not so well, but there's room for improvement.**\n",
    "\n",
    "> **Jager's note:** This classifier is great for interpolation, ie predicting prices based on reviews which lie within the set of reviews the model was trained on. **This is due to the varied vocabulary of the sommelier.**  The model fails to extrapolate to the test set, also due to the varied nature of the vocabulary.  A negative R2 score reported by sklearn means the model performs arbitrarily worse than just guessing the mean price.\n",
    "\n",
    "Why didn't we do so well? Basically, our model paying a lot of attention to **very specific words** from the training set, and then gets confused when it doesn't see those words in the test data. We should probably have it trained with  **more general words!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.3: Having a little fun for a second\n",
    "\n",
    "Let's use our regression to test a couple reviews we wrote ourselves! We use **vec.transform** here instead of `fit_transform` because \"fit\" means \"learn words\" but here we just want to say \"hey we know the words already, just count the ones we've seen before.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10.55603911,  30.36262418])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this, see the prices. Then change 'hills' to 'hillsides'\n",
    "samples = [\n",
    "    \"This Alsacian wine smells like blueberries and cherries\",\n",
    "    \"A hand-crafted red from the sun swept hills of China\"\n",
    "]\n",
    "matrix = vec.transform(samples)\n",
    "lr.predict(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Understanding the components of our model\n",
    "\n",
    "We're going to use this code that Jager so kindly wrote for us! You can change the `n = 10` line if you want to see more or fewer variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest Contributors to High Price\n",
      "\n",
      "expansive 28.238131849\n",
      "chocolaty 28.4994276672\n",
      "peppercorn 29.3282793048\n",
      "ll 31.5578864525\n",
      "cherry cassis 33.5772501008\n",
      "charred 34.3414600864\n",
      "seamless 38.7384918402\n",
      "petit verdot 42.1924777363\n",
      "coffee bean 48.5842990317\n",
      "lip smacking 58.9694194767\n",
      "\n",
      "\n",
      "Largest Contributors to Low Price\n",
      "\n",
      "decent -20.4865857557\n",
      "new leather -22.2599221879\n",
      "tilled -22.7344501559\n",
      "herb cherry -22.9483144095\n",
      "bone dry -23.4254817587\n",
      "tannins leave -29.61429592\n",
      "smacking -30.6271449712\n",
      "blackberry jam -30.9546531822\n",
      "doles -31.1625751361\n",
      "roasted coffee -40.4129556457\n",
      "petit -43.7625182747\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    print('\\n--------------------------------\\n')\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % (topic_idx+1))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "n = 10        \n",
    "bottom_n = np.argsort(lr.coef_)[n::-1]\n",
    "top_n = np.argsort(lr.coef_)[-n:]\n",
    "\n",
    "feature_names = vec.get_feature_names()\n",
    "\n",
    "print('Largest Contributors to High Price\\n')\n",
    "print(\"\\n\".join(feature_names[i] + \" \" + str(lr.coef_[i]) for i in top_n))\n",
    "\n",
    "print('\\n\\nLargest Contributors to Low Price\\n')\n",
    "print(\"\\n\".join(feature_names[i] + \" \" + str(lr.coef_[i]) for i in bottom_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Those words probably seem... kind of stupid. \n",
    "\n",
    "## !!! Your assignment is to improve our measurements and get some sensible words in these lists!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# All of the code in one small-ish area, plus some secret stuff\n",
    "\n",
    "If you don't need the walkthrough and the explanations, here's everyting all at once! You can import the data up at the top, and then use this area to play around with vectorizing variables.\n",
    "\n",
    "### The secrets to getting a better score\n",
    "\n",
    "If your r-square is **higher** then you're doing **better**. How high can you get it? Here are some tips:\n",
    "\n",
    "* Right now your model is paying too much attention to **rare words**, words that show up **infrequently**. Is there an option you can give your vectorizer to not pay attention to rare words?\n",
    "* I know we talk bad about multiple-word phrases, but \"red fruit\" versus \"citrus fruit\" might be important here.\n",
    "* Try to add **categorical variables** as features. You can't just say \"Red is 0, White is 1, etc,\" but I've included some code to show you how to do it!\n",
    "* I don't know, just keep running with those ideas!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize\n",
    "\n",
    "Pay attention to how many columns you have down below. More words = more columns, but that doesn't mean a better result! How can you get rid of words that don't show up that often?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abound</th>\n",
       "      <th>abounds</th>\n",
       "      <th>abrasive</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abundance</th>\n",
       "      <th>abundant</th>\n",
       "      <th>acacia</th>\n",
       "      <th>...</th>\n",
       "      <th>yummy</th>\n",
       "      <th>zest</th>\n",
       "      <th>zestiness</th>\n",
       "      <th>zesty</th>\n",
       "      <th>zinfandel</th>\n",
       "      <th>zing</th>\n",
       "      <th>zingy</th>\n",
       "      <th>zip</th>\n",
       "      <th>zippy</th>\n",
       "      <th>émilion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 3000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandon  abound  abounds  abrasive  abrupt  absolute  absolutely  \\\n",
       "0        0       0        0         0       0         0           0   \n",
       "1        0       0        0         0       0         0           0   \n",
       "\n",
       "   abundance  abundant  acacia   ...     yummy  zest  zestiness  zesty  \\\n",
       "0          0         0       0   ...         0     0          0      0   \n",
       "1          0         0       0   ...         0     0          0      0   \n",
       "\n",
       "   zinfandel  zing  zingy  zip  zippy  émilion  \n",
       "0          0     0      0    0      0        0  \n",
       "1          0     0      0    0      0        0  \n",
       "\n",
       "[2 rows x 3000 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer(stop_words = 'english', max_features=3000)\n",
    "# Let's also remove numbers before we count words\n",
    "matrix = vec.fit_transform(df['wine_desc'].str.replace(\"\\d\",\"\"))\n",
    "features_df = pd.DataFrame(matrix.toarray(), columns=vec.get_feature_names())\n",
    "\n",
    "features_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special secret: Adding categorical variables\n",
    "\n",
    "Want do use this? Uncomment it! Scroll down a lot to read why and how this works. You don't need to do this if you don't want to, it might get overly complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abound</th>\n",
       "      <th>abounds</th>\n",
       "      <th>abrasive</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abundance</th>\n",
       "      <th>abundant</th>\n",
       "      <th>acacia</th>\n",
       "      <th>...</th>\n",
       "      <th>zing</th>\n",
       "      <th>zingy</th>\n",
       "      <th>zip</th>\n",
       "      <th>zippy</th>\n",
       "      <th>émilion</th>\n",
       "      <th>CUSTOM_Port/Sherry</th>\n",
       "      <th>CUSTOM_Red</th>\n",
       "      <th>CUSTOM_Rose</th>\n",
       "      <th>CUSTOM_Sparkling</th>\n",
       "      <th>CUSTOM_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 3005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandon  abound  abounds  abrasive  abrupt  absolute  absolutely  \\\n",
       "0        0       0        0         0       0         0           0   \n",
       "1        0       0        0         0       0         0           0   \n",
       "\n",
       "   abundance  abundant  acacia      ...       zing  zingy  zip  zippy  \\\n",
       "0          0         0       0      ...          0      0    0      0   \n",
       "1          0         0       0      ...          0      0    0      0   \n",
       "\n",
       "   émilion  CUSTOM_Port/Sherry  CUSTOM_Red  CUSTOM_Rose  CUSTOM_Sparkling  \\\n",
       "0        0                 0.0         1.0          0.0               0.0   \n",
       "1        0                 0.0         0.0          0.0               0.0   \n",
       "\n",
       "   CUSTOM_White  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "\n",
       "[2 rows x 3005 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can only run this once!!! Then you'll get an error because of duplicate columns.\n",
    "# If you get an error, re-run your vectorizer up above.\n",
    "\n",
    "custom = pd.get_dummies(df['category'], prefix=\"CUSTOM\", drop_first=True)\n",
    "features_df = features_df.join(custom).fillna(0)\n",
    "features_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to remove custom columns that aren't used that often, use the code below. This is kind of like `min_idf`! So for example, the `features_df[custom_columns].mean() < 0.005` part below says **remove any custom columns that only show up in less than 0.5% of rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing column []\n"
     ]
    }
   ],
   "source": [
    "custom_columns = features_df.columns[features_df.columns.str.contains(\"CUSTOM\")]\n",
    "low_frequency = custom_columns[features_df[custom_columns].mean() < 0.005]\n",
    "print(\"Removing column\", list(low_frequency))\n",
    "features_df.drop(low_frequency, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test/train split + regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on train: 0.999951954527 \n",
      "Mean Squared Error on train: 0.0389273689806\n",
      "R2 on test: -2.29327752598e+21 \n",
      "Mean Squared Error on train: 2.0056767367e+24\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_df.values, # these are our words\n",
    "    df.price_int, # these are our prices\n",
    "    test_size = 0.2)\n",
    "\n",
    "lr = LinearRegression(fit_intercept = 0)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print('R2 on train:', r2_score(y_train, lr.predict(X_train)), '\\nMean Squared Error on train:', mean_squared_error(y_train, lr.predict(X_train)))\n",
    "\n",
    "print('R2 on test:', r2_score(y_test, lr.predict(X_test)), '\\nMean Squared Error on train:', mean_squared_error(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the important words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    print('\\n--------------------------------\\n')\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % (topic_idx+1))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "n = 10        \n",
    "bottom_n = np.argsort(lr.coef_)[n::-1]\n",
    "top_n = np.argsort(lr.coef_)[-n:]\n",
    "\n",
    "feature_names = list(features_df.columns)\n",
    "\n",
    "print('Largest Contributors to High Price:\\n')\n",
    "print(\"\\n\".join(feature_names[i] + \" \" + str(lr.coef_[i]) for i in top_n))\n",
    "\n",
    "print('\\n\\nLargest Contributors to Low Price:\\n')\n",
    "print(\"\\n\".join(feature_names[i] + \" \" + str(lr.coef_[i]) for i in bottom_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPECIAL SECRET: How to add features based on a category column (e.g. winery, type of wine, etc)\n",
    "\n",
    "When using categorical variables in a regression, you want to take something like...\n",
    "\n",
    "|Wine|Category|\n",
    "|---|---|\n",
    "|0|Red|\n",
    "|1|Red|\n",
    "|2|White|\n",
    "|3|Dessert|\n",
    "\n",
    "and turn it into features that look like this:\n",
    "\n",
    "|CUSTOM_Red|CUSTOM_White|CUSTOM_Dessert|\n",
    "|---|---|---|\n",
    "|1|0|0|\n",
    "|1|0|0|\n",
    "|0|1|0|\n",
    "|0|0|1|\n",
    "\n",
    "(Except only kind of, because of [the dummy variable trap](http://www.algosome.com/articles/dummy-variable-trap-regression.html)) But hey, who cares, whatever, now you know about the hilariously-named `pd.get_dummies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['category'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(df['category'], prefix=\"CUSTOM\", drop_first=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You use `drop_first=True` to make `Dessert Wine` not be a category, because of that \"dummy trap\" thing I mentioned up above. And we prefix it with \"CUSTOM\" to keep it different from actual words used.\n",
    "\n",
    "You can see this in use up above near the \"Vectorize\" section - I just commented it out so it wouldn't get in the way.\n",
    "\n",
    "**I\"d be happy to talk more about this with you!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
